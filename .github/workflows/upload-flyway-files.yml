name: ✳️ Upload Flyway files to S3

on:
  workflow_call:
    inputs:
      environment:
        type: string
        required: true
      skip-upload-libraries:
        type: boolean
        required: false
        default: true
  workflow_dispatch:
    inputs:
      environment:
        type: choice
        required: true
        description: AWS environment
        options: [DEV, TEST, FEATURE, BUILD, STAGING, INTEGRATION, PRODUCTION, PRODUCTION-PREVIEW]
      skip-upload-libraries:
        type: boolean
        required: false
        description: Skip uploading flyway tar and redshift jar as it is slow to do so and it only needs to be done if they have changed
        default: true

jobs:
  validate-environment:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
      - name: Validate input environment
        run: scripts/validate-environment.sh ${{ inputs.environment }}

  upload-to-s3:
    needs: [validate-environment]
    # These permissions are needed to interact with GitHub's OIDC Token endpoint (enabling the aws-actions/configure-aws-credentials action)
    permissions:
      id-token: write
      contents: read
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          lfs: true
      - name: Assume AWS GitHub actions role
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: eu-west-2
          role-to-assume: ${{ secrets.FLYWAY_FILES_UPLOAD_ROLE_ARN }}
      - name: Upload athena files to S3
        run: |
          REGION="eu-west-2"
          FILES_ROOT="redshift-scripts/flyway"
          S3_BUCKET="s3://$(echo "${{ inputs.environment }}" | tr '[:upper:]' '[:lower:]')-dap-flyway-files"

          echo "Uploading contents of $FILES_ROOT to bucket $S3_BUCKET (skip-upload-libraries: ${{ inputs.skip-upload-libraries }})"          
          if [ ${{ inputs.skip-upload-libraries }} == "true" ]; then
            aws --region="$REGION" s3 cp "$FILES_ROOT" "$S3_BUCKET" --recursive --exclude "lib/*"
          else
            aws --region="$REGION" s3 rm "$S3_BUCKET"/lib --recursive
            aws --region="$REGION" s3 cp "$FILES_ROOT" "$S3_BUCKET" --recursive
          fi
